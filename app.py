
import streamlit as st
from ibm_watsonx_ai.foundation_models import ModelInference
from ibm_watsonx_ai import Credentials

# IBM Credentials
api_key = "your_ibm_api_key"
project_id = "your_project_id"
credentials = Credentials(api_key=api_key, url="https://us-south.ml.cloud.ibm.com")

model = ModelInference(
    model_id="google/flan-ul2",
    params={"decoding_method": "greedy", "max_new_tokens": 800},
    project_id=project_id,
    credentials=credentials,
)

st.title("ЁЯОУ EduTutor AI - Explain & Quiz (Hindi/English)")

language = st.radio("Choose Language / рднрд╛рд╖рд╛ рдЪреБрдиреЗрдВ:", ["English", "Hindi"])
topic = st.text_input("Enter a topic / рд╡рд┐рд╖рдп рджрд░реНрдЬ рдХрд░реЗрдВ (e.g., Photosynthesis, рдкреНрд░рдХрд╛рд╢ рд╕рдВрд╢реНрд▓реЗрд╖рдг):")
mode = st.radio("Choose Mode:", ["Topic Explanation", "MCQ Generator"])

if st.button("Generate") and topic.strip():
    if language == "Hindi":
        topic_lang = "рд╣рд┐рдВрджреА рдореЗрдВ"
        explain_prompt = f""{topic}" рд╡рд┐рд╖рдп рдХреЛ рд╡рд┐рд╕реНрддрд╛рд░ рд╕реЗ рд╕рдордЭрд╛рдЗрдПред"
        mcq_prompt = f"{topic} рд╡рд┐рд╖рдп рдкрд░ 5 рдмрд╣реБрд╡рд┐рдХрд▓реНрдкреАрдп рдкреНрд░рд╢реНрди рд╣рд┐рдВрджреА рдореЗрдВ рддреИрдпрд╛рд░ рдХрд░реЗрдВред рд╣рд░ рдкреНрд░рд╢реНрди рдХреЗ рдЪрд╛рд░ рд╡рд┐рдХрд▓реНрдк (A, B, C, D) рдФрд░ рдЙрддреНрддрд░ рд╕рд╣рд┐рддред"
    else:
        topic_lang = "in English"
        explain_prompt = f"Explain the topic "{topic}" in detail in simple English."
        mcq_prompt = f"Generate 5 multiple choice questions {topic_lang} on the topic "{topic}" with four options (A, B, C, D) and mention the correct answer."

    if mode == "Topic Explanation":
        with st.spinner("Generating explanation..."):
            response = model.generate(prompt=explain_prompt)
            st.subheader("ЁЯУШ Topic Explanation / рд╡рд┐рд╖рдп рд╡реНрдпрд╛рдЦреНрдпрд╛")
            st.write(response)
    else:
        with st.spinner("Generating MCQs..."):
            response = model.generate(prompt=mcq_prompt)
            st.subheader("ЁЯУЭ Generated MCQs / рдЕрднреНрдпрд╛рд╕ рдкреНрд░рд╢реНрди")
            st.text_area("MCQs", response, height=400)
